---
layout: page
title: Smooth game optimization for machine learning
description: Unified analyses and accelerated methods for differentiable games.
importance: 6
category: research
---

To address the challenges of multi-agent optimization, the machine learning community has started designing bespoke first-order methods for games. With [Gauthier Gidel](https://gauthiergidel.github.io/), [Ioannis Mitliagkas](https://mitliagkas.github.io/) and [Simon Lacoste-Julien](https://www.iro.umontreal.ca/~slacoste/), we provided the first tight and unified analysis of several gradient-based methods that showcased their different convergence mechanisms ([AISTATS 20](https://arxiv.org/abs/1906.05945), [slides](/assets/pdf/slides_aistats.pdf)).

We also tackled the question of possible acceleration of these methods, providing both lower-bounds for general classes of games and the first momentum-accelerated methods for games by leveraging matrix iteration theory ([AISTATS 20](https://arxiv.org/abs/2001.00602)).
